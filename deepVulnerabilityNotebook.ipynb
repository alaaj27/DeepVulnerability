{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rapid-director",
   "metadata": {},
   "source": [
    "## Multimodal Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brilliant-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operational-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_Autoencoder(nn.Module):\n",
    "    \"\"\"Autoencoder\"\"\"\n",
    "    def __init__(self, n_input, latent_variable_size, n_hidden=512):\n",
    "        super(FC_Autoencoder, self).__init__()\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.n_input, n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(n_hidden, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(n_hidden, latent_variable_size)\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_variable_size, n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_input),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        latent_space = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(latent_space)\n",
    "        return res, latent_space, mu, logvar\n",
    "    \n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)       \n",
    "        return self.fc1(h), self.fc2(h)\n",
    "\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    " \n",
    "    def generate(self, z):\n",
    "        res = self.decode(z)\n",
    "        return res\n",
    "\n",
    "    \n",
    "class FC_Classifier(nn.Module):\n",
    "    \"\"\"Latent space discriminator\"\"\"\n",
    "    def __init__(self, latent_variable_size, n_hidden=1024, n_out=2):\n",
    "        super(FC_Classifier, self).__init__()\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_variable_size, n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "#            nn.Linear(n_hidden, n_hidden),\n",
    "#            nn.ReLU(inplace=True),\n",
    " #           nn.Linear(n_hidden, n_hidden),\n",
    " #           nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden,n_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (Essentiality, Expression, total_unique_cells = 1499):\n",
    "\n",
    "    dataset_processed = dict()\n",
    "    common_cells = set(Essentiality.index) & set(Expression.index)  \n",
    "    \n",
    "    for cell in common_cells:\n",
    "\n",
    "        dataset_processed[cell] = {\n",
    "            \"data_ess\": torch.tensor(Essentiality.loc[cell]),\n",
    "            \"data_exp\": torch.tensor(Expression.loc[cell]),\n",
    "            \"label\": hash(cell) % total_unique_cells\n",
    "        }\n",
    "    return dataset_processed\n",
    "\n",
    "\n",
    "class JointDataset(Dataset):\n",
    "    def __init__(self, dataset, from_keys):\n",
    "        \n",
    "        self.data_ess = []\n",
    "        self.data_exp = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for cell in from_keys: #dataset.keys():\n",
    "            self.data_ess.append(dataset[cell][\"data_ess\"])\n",
    "            self.data_exp.append(dataset[cell][\"data_exp\"])\n",
    "            self.labels.append(dataset[cell][\"label\"])\n",
    "        \n",
    "        self.data_ess = torch.stack(self.data_ess).float()\n",
    "        self.data_exp = torch.stack(self.data_exp).float()\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data_ess[index], self.data_exp[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-secretariat",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legitimate-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "Essentiality = pd.read_csv(\"~/deepVul/data/CRISPRGeneEffect.csv\").rename(\n",
    "    columns={\"Unnamed: 0\": 'CellLine'}).set_index('CellLine')\n",
    "\n",
    "Expression = pd.read_csv(\"~/deepVul/data/OmicsExpressionProteinCodingGenesTPMLogp1.csv\").rename(\n",
    "    columns={\"Unnamed: 0\": 'CellLine'}).set_index('CellLine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polar-occasions",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG (1)</th>\n",
       "      <th>A1CF (29974)</th>\n",
       "      <th>A2M (2)</th>\n",
       "      <th>A2ML1 (144568)</th>\n",
       "      <th>A3GALT2 (127550)</th>\n",
       "      <th>A4GALT (53947)</th>\n",
       "      <th>A4GNT (51146)</th>\n",
       "      <th>AAAS (8086)</th>\n",
       "      <th>AACS (65985)</th>\n",
       "      <th>AADAC (13)</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH (55055)</th>\n",
       "      <th>ZWINT (11130)</th>\n",
       "      <th>ZXDA (7789)</th>\n",
       "      <th>ZXDB (158586)</th>\n",
       "      <th>ZXDC (79364)</th>\n",
       "      <th>ZYG11A (440590)</th>\n",
       "      <th>ZYG11B (79699)</th>\n",
       "      <th>ZYX (7791)</th>\n",
       "      <th>ZZEF1 (23140)</th>\n",
       "      <th>ZZZ3 (26009)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CellLine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-000004</th>\n",
       "      <td>0.014633</td>\n",
       "      <td>-0.032777</td>\n",
       "      <td>-0.151299</td>\n",
       "      <td>-0.071388</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>-0.162850</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>-0.240991</td>\n",
       "      <td>0.176710</td>\n",
       "      <td>0.159418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188857</td>\n",
       "      <td>-0.389649</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>-0.002883</td>\n",
       "      <td>0.155729</td>\n",
       "      <td>0.077283</td>\n",
       "      <td>-0.294451</td>\n",
       "      <td>0.143978</td>\n",
       "      <td>0.197069</td>\n",
       "      <td>-0.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000005</th>\n",
       "      <td>-0.261566</td>\n",
       "      <td>0.174833</td>\n",
       "      <td>0.106526</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>-0.076753</td>\n",
       "      <td>-0.278640</td>\n",
       "      <td>0.239279</td>\n",
       "      <td>-0.325967</td>\n",
       "      <td>-0.116848</td>\n",
       "      <td>0.022227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195492</td>\n",
       "      <td>-0.360578</td>\n",
       "      <td>-0.126277</td>\n",
       "      <td>-0.059287</td>\n",
       "      <td>0.080543</td>\n",
       "      <td>-0.161894</td>\n",
       "      <td>-0.070230</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.014259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000007</th>\n",
       "      <td>-0.028717</td>\n",
       "      <td>-0.117017</td>\n",
       "      <td>0.030971</td>\n",
       "      <td>0.083795</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>-0.035709</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>-0.192436</td>\n",
       "      <td>-0.077174</td>\n",
       "      <td>0.164877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200402</td>\n",
       "      <td>-0.382707</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.199553</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>-0.031683</td>\n",
       "      <td>-0.291406</td>\n",
       "      <td>-0.065945</td>\n",
       "      <td>-0.260946</td>\n",
       "      <td>-0.329018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000009</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.283124</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>0.120321</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>-0.077522</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>-0.190495</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.043242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179775</td>\n",
       "      <td>-0.285412</td>\n",
       "      <td>-0.029599</td>\n",
       "      <td>0.227176</td>\n",
       "      <td>-0.097506</td>\n",
       "      <td>-0.136990</td>\n",
       "      <td>-0.421927</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>-0.107675</td>\n",
       "      <td>-0.249623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000011</th>\n",
       "      <td>0.095791</td>\n",
       "      <td>-0.099622</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.199771</td>\n",
       "      <td>-0.048126</td>\n",
       "      <td>-0.290812</td>\n",
       "      <td>-0.013277</td>\n",
       "      <td>-0.095840</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>0.029379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671885</td>\n",
       "      <td>-0.558008</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.206251</td>\n",
       "      <td>0.086453</td>\n",
       "      <td>-0.166360</td>\n",
       "      <td>-0.055975</td>\n",
       "      <td>-0.159886</td>\n",
       "      <td>-0.311232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002296</th>\n",
       "      <td>-0.073879</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>-0.077086</td>\n",
       "      <td>0.028623</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>-1.143038</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.115898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135984</td>\n",
       "      <td>-0.666816</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>0.157030</td>\n",
       "      <td>-0.054452</td>\n",
       "      <td>-0.260831</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.041468</td>\n",
       "      <td>-0.428699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002297</th>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.249753</td>\n",
       "      <td>0.045093</td>\n",
       "      <td>0.070714</td>\n",
       "      <td>-0.194074</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>-0.029772</td>\n",
       "      <td>-0.743310</td>\n",
       "      <td>0.081368</td>\n",
       "      <td>0.155969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407122</td>\n",
       "      <td>-0.473605</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.153230</td>\n",
       "      <td>-0.066343</td>\n",
       "      <td>0.029340</td>\n",
       "      <td>-0.120501</td>\n",
       "      <td>-0.058169</td>\n",
       "      <td>-0.179429</td>\n",
       "      <td>-0.172884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002298</th>\n",
       "      <td>-0.172365</td>\n",
       "      <td>-0.112164</td>\n",
       "      <td>0.055771</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.010154</td>\n",
       "      <td>-0.069917</td>\n",
       "      <td>-0.092145</td>\n",
       "      <td>-0.135460</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>-0.132641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270696</td>\n",
       "      <td>-0.383323</td>\n",
       "      <td>0.101514</td>\n",
       "      <td>0.101316</td>\n",
       "      <td>0.110317</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>-0.158971</td>\n",
       "      <td>-0.114161</td>\n",
       "      <td>0.128512</td>\n",
       "      <td>-0.267323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002304</th>\n",
       "      <td>-0.033065</td>\n",
       "      <td>0.171028</td>\n",
       "      <td>-0.044622</td>\n",
       "      <td>0.185127</td>\n",
       "      <td>0.063611</td>\n",
       "      <td>-0.047573</td>\n",
       "      <td>0.118359</td>\n",
       "      <td>-0.571989</td>\n",
       "      <td>-0.101702</td>\n",
       "      <td>0.263272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106406</td>\n",
       "      <td>-0.300325</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>-0.176315</td>\n",
       "      <td>-0.054927</td>\n",
       "      <td>-0.079415</td>\n",
       "      <td>-0.130105</td>\n",
       "      <td>0.133510</td>\n",
       "      <td>-0.126235</td>\n",
       "      <td>-0.211761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002305</th>\n",
       "      <td>0.076307</td>\n",
       "      <td>-0.241877</td>\n",
       "      <td>0.165187</td>\n",
       "      <td>-0.088436</td>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.115397</td>\n",
       "      <td>-0.065532</td>\n",
       "      <td>-0.587833</td>\n",
       "      <td>0.080505</td>\n",
       "      <td>-0.079979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308187</td>\n",
       "      <td>-0.824144</td>\n",
       "      <td>-0.183761</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.215163</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>-0.107611</td>\n",
       "      <td>-0.108798</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>-0.291455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1078 rows × 17453 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A1BG (1)  A1CF (29974)   A2M (2)  A2ML1 (144568)  \\\n",
       "CellLine                                                       \n",
       "ACH-000004  0.014633     -0.032777 -0.151299       -0.071388   \n",
       "ACH-000005 -0.261566      0.174833  0.106526        0.135635   \n",
       "ACH-000007 -0.028717     -0.117017  0.030971        0.083795   \n",
       "ACH-000009  0.000225     -0.283124  0.051248        0.120321   \n",
       "ACH-000011  0.095791     -0.099622  0.022204        0.199771   \n",
       "...              ...           ...       ...             ...   \n",
       "ACH-002296 -0.073879      0.046252 -0.077086        0.028623   \n",
       "ACH-002297  0.084735     -0.249753  0.045093        0.070714   \n",
       "ACH-002298 -0.172365     -0.112164  0.055771       -0.017571   \n",
       "ACH-002304 -0.033065      0.171028 -0.044622        0.185127   \n",
       "ACH-002305  0.076307     -0.241877  0.165187       -0.088436   \n",
       "\n",
       "            A3GALT2 (127550)  A4GALT (53947)  A4GNT (51146)  AAAS (8086)  \\\n",
       "CellLine                                                                   \n",
       "ACH-000004          0.046511       -0.162850       0.290698    -0.240991   \n",
       "ACH-000005         -0.076753       -0.278640       0.239279    -0.325967   \n",
       "ACH-000007          0.032668       -0.035709       0.012355    -0.192436   \n",
       "ACH-000009          0.022834       -0.077522       0.028013    -0.190495   \n",
       "ACH-000011         -0.048126       -0.290812      -0.013277    -0.095840   \n",
       "...                      ...             ...            ...          ...   \n",
       "ACH-002296         -0.000662        0.003801       0.023230    -1.143038   \n",
       "ACH-002297         -0.194074       -0.038278      -0.029772    -0.743310   \n",
       "ACH-002298         -0.010154       -0.069917      -0.092145    -0.135460   \n",
       "ACH-002304          0.063611       -0.047573       0.118359    -0.571989   \n",
       "ACH-002305          0.031024        0.115397      -0.065532    -0.587833   \n",
       "\n",
       "            AACS (65985)  AADAC (13)  ...  ZWILCH (55055)  ZWINT (11130)  \\\n",
       "CellLine                              ...                                  \n",
       "ACH-000004      0.176710    0.159418  ...       -0.188857      -0.389649   \n",
       "ACH-000005     -0.116848    0.022227  ...       -0.195492      -0.360578   \n",
       "ACH-000007     -0.077174    0.164877  ...       -0.200402      -0.382707   \n",
       "ACH-000009      0.031589    0.043242  ...       -0.179775      -0.285412   \n",
       "ACH-000011      0.090307    0.029379  ...       -0.671885      -0.558008   \n",
       "...                  ...         ...  ...             ...            ...   \n",
       "ACH-002296      0.004579    0.115898  ...        0.135984      -0.666816   \n",
       "ACH-002297      0.081368    0.155969  ...       -0.407122      -0.473605   \n",
       "ACH-002298      0.008202   -0.132641  ...       -0.270696      -0.383323   \n",
       "ACH-002304     -0.101702    0.263272  ...        0.106406      -0.300325   \n",
       "ACH-002305      0.080505   -0.079979  ...       -0.308187      -0.824144   \n",
       "\n",
       "            ZXDA (7789)  ZXDB (158586)  ZXDC (79364)  ZYG11A (440590)  \\\n",
       "CellLine                                                                \n",
       "ACH-000004     0.112266      -0.002883      0.155729         0.077283   \n",
       "ACH-000005    -0.126277      -0.059287      0.080543        -0.161894   \n",
       "ACH-000007     0.006843       0.199553      0.064425        -0.031683   \n",
       "ACH-000009    -0.029599       0.227176     -0.097506        -0.136990   \n",
       "ACH-000011     0.020997       0.011011      0.206251         0.086453   \n",
       "...                 ...            ...           ...              ...   \n",
       "ACH-002296     0.015930      -0.000437      0.157030        -0.054452   \n",
       "ACH-002297    -0.000171       0.153230     -0.066343         0.029340   \n",
       "ACH-002298     0.101514       0.101316      0.110317        -0.006500   \n",
       "ACH-002304    -0.034307      -0.176315     -0.054927        -0.079415   \n",
       "ACH-002305    -0.183761       0.006969      0.215163         0.010098   \n",
       "\n",
       "            ZYG11B (79699)  ZYX (7791)  ZZEF1 (23140)  ZZZ3 (26009)  \n",
       "CellLine                                                             \n",
       "ACH-000004       -0.294451    0.143978       0.197069     -0.003338  \n",
       "ACH-000005       -0.070230   -0.006275       0.002458      0.014259  \n",
       "ACH-000007       -0.291406   -0.065945      -0.260946     -0.329018  \n",
       "ACH-000009       -0.421927    0.050002      -0.107675     -0.249623  \n",
       "ACH-000011       -0.166360   -0.055975      -0.159886     -0.311232  \n",
       "...                    ...         ...            ...           ...  \n",
       "ACH-002296       -0.260831    0.064285       0.041468     -0.428699  \n",
       "ACH-002297       -0.120501   -0.058169      -0.179429     -0.172884  \n",
       "ACH-002298       -0.158971   -0.114161       0.128512     -0.267323  \n",
       "ACH-002304       -0.130105    0.133510      -0.126235     -0.211761  \n",
       "ACH-002305       -0.107611   -0.108798       0.001063     -0.291455  \n",
       "\n",
       "[1078 rows x 17453 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Essentiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-collective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSPAN6 (7105)</th>\n",
       "      <th>TNMD (64102)</th>\n",
       "      <th>DPM1 (8813)</th>\n",
       "      <th>SCYL3 (57147)</th>\n",
       "      <th>C1orf112 (55732)</th>\n",
       "      <th>FGR (2268)</th>\n",
       "      <th>CFH (3075)</th>\n",
       "      <th>FUCA2 (2519)</th>\n",
       "      <th>GCLC (2729)</th>\n",
       "      <th>NFYA (4800)</th>\n",
       "      <th>...</th>\n",
       "      <th>H3C2 (8358)</th>\n",
       "      <th>H3C3 (8352)</th>\n",
       "      <th>AC098582.1 (8916)</th>\n",
       "      <th>DUS4L-BCAP29 (115253422)</th>\n",
       "      <th>C8orf44-SGK3 (100533105)</th>\n",
       "      <th>ELOA3B (728929)</th>\n",
       "      <th>NPBWR1 (2831)</th>\n",
       "      <th>ELOA3D (100506888)</th>\n",
       "      <th>ELOA3 (162699)</th>\n",
       "      <th>CDR1 (1038)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CellLine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-001113</th>\n",
       "      <td>4.331992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.364660</td>\n",
       "      <td>2.792855</td>\n",
       "      <td>4.471187</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>1.226509</td>\n",
       "      <td>3.044394</td>\n",
       "      <td>6.500005</td>\n",
       "      <td>4.739848</td>\n",
       "      <td>...</td>\n",
       "      <td>2.689299</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>2.130931</td>\n",
       "      <td>0.555816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001289</th>\n",
       "      <td>4.567424</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>7.106641</td>\n",
       "      <td>2.543496</td>\n",
       "      <td>3.504620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>3.813525</td>\n",
       "      <td>4.221877</td>\n",
       "      <td>3.481557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286881</td>\n",
       "      <td>1.049631</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>1.464668</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001339</th>\n",
       "      <td>3.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.379118</td>\n",
       "      <td>2.333424</td>\n",
       "      <td>4.228049</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.310340</td>\n",
       "      <td>6.687201</td>\n",
       "      <td>3.682573</td>\n",
       "      <td>3.273516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594549</td>\n",
       "      <td>1.097611</td>\n",
       "      <td>0.831877</td>\n",
       "      <td>2.946731</td>\n",
       "      <td>0.475085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001538</th>\n",
       "      <td>5.085340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.154211</td>\n",
       "      <td>2.545968</td>\n",
       "      <td>3.084064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.868390</td>\n",
       "      <td>6.165309</td>\n",
       "      <td>4.489928</td>\n",
       "      <td>3.956986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>1.641546</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000242</th>\n",
       "      <td>6.729417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.537917</td>\n",
       "      <td>2.456806</td>\n",
       "      <td>3.867896</td>\n",
       "      <td>0.799087</td>\n",
       "      <td>7.208478</td>\n",
       "      <td>5.570159</td>\n",
       "      <td>7.127117</td>\n",
       "      <td>4.568032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117695</td>\n",
       "      <td>2.358959</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>1.910733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000285</th>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.604368</td>\n",
       "      <td>3.266037</td>\n",
       "      <td>4.973152</td>\n",
       "      <td>0.411426</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>4.829850</td>\n",
       "      <td>5.178715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.229588</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>1.310340</td>\n",
       "      <td>3.039138</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475085</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-002669</th>\n",
       "      <td>3.111031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.031329</td>\n",
       "      <td>1.541019</td>\n",
       "      <td>3.664483</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>3.624101</td>\n",
       "      <td>6.805421</td>\n",
       "      <td>4.472488</td>\n",
       "      <td>4.397118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>1.327687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001858</th>\n",
       "      <td>4.390943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.013239</td>\n",
       "      <td>1.887525</td>\n",
       "      <td>3.252476</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>3.286881</td>\n",
       "      <td>6.902194</td>\n",
       "      <td>5.410748</td>\n",
       "      <td>3.401903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.097611</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.613532</td>\n",
       "      <td>1.992768</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.464668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001997</th>\n",
       "      <td>5.057450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.815191</td>\n",
       "      <td>2.538538</td>\n",
       "      <td>3.893362</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.079805</td>\n",
       "      <td>6.971659</td>\n",
       "      <td>4.469886</td>\n",
       "      <td>3.463361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831877</td>\n",
       "      <td>0.847997</td>\n",
       "      <td>1.292782</td>\n",
       "      <td>2.153805</td>\n",
       "      <td>0.687061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000052</th>\n",
       "      <td>4.249445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.175724</td>\n",
       "      <td>2.319040</td>\n",
       "      <td>3.825786</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>1.321928</td>\n",
       "      <td>3.538538</td>\n",
       "      <td>3.945795</td>\n",
       "      <td>4.469886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244887</td>\n",
       "      <td>1.207893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.956057</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.056584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows × 19193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSPAN6 (7105)  TNMD (64102)  DPM1 (8813)  SCYL3 (57147)  \\\n",
       "CellLine                                                              \n",
       "ACH-001113       4.331992      0.000000     7.364660       2.792855   \n",
       "ACH-001289       4.567424      0.584963     7.106641       2.543496   \n",
       "ACH-001339       3.150560      0.000000     7.379118       2.333424   \n",
       "ACH-001538       5.085340      0.000000     7.154211       2.545968   \n",
       "ACH-000242       6.729417      0.000000     6.537917       2.456806   \n",
       "...                   ...           ...          ...            ...   \n",
       "ACH-000285       0.056584      0.000000     6.604368       3.266037   \n",
       "ACH-002669       3.111031      0.000000     7.031329       1.541019   \n",
       "ACH-001858       4.390943      0.000000     7.013239       1.887525   \n",
       "ACH-001997       5.057450      0.000000     7.815191       2.538538   \n",
       "ACH-000052       4.249445      0.000000     6.175724       2.319040   \n",
       "\n",
       "            C1orf112 (55732)  FGR (2268)  CFH (3075)  FUCA2 (2519)  \\\n",
       "CellLine                                                             \n",
       "ACH-001113          4.471187    0.028569    1.226509      3.044394   \n",
       "ACH-001289          3.504620    0.000000    0.189034      3.813525   \n",
       "ACH-001339          4.228049    0.056584    1.310340      6.687201   \n",
       "ACH-001538          3.084064    0.000000    5.868390      6.165309   \n",
       "ACH-000242          3.867896    0.799087    7.208478      5.570159   \n",
       "...                      ...         ...         ...           ...   \n",
       "ACH-000285          4.973152    0.411426    0.097611      0.704872   \n",
       "ACH-002669          3.664483    0.014355    3.624101      6.805421   \n",
       "ACH-001858          3.252476    0.028569    3.286881      6.902194   \n",
       "ACH-001997          3.893362    0.028569    4.079805      6.971659   \n",
       "ACH-000052          3.825786    0.189034    1.321928      3.538538   \n",
       "\n",
       "            GCLC (2729)  NFYA (4800)  ...  H3C2 (8358)  H3C3 (8352)  \\\n",
       "CellLine                              ...                             \n",
       "ACH-001113     6.500005     4.739848  ...     2.689299     0.189034   \n",
       "ACH-001289     4.221877     3.481557  ...     1.286881     1.049631   \n",
       "ACH-001339     3.682573     3.273516  ...     0.594549     1.097611   \n",
       "ACH-001538     4.489928     3.956986  ...     0.214125     0.632268   \n",
       "ACH-000242     7.127117     4.568032  ...     1.117695     2.358959   \n",
       "...                 ...          ...  ...          ...          ...   \n",
       "ACH-000285     4.829850     5.178715  ...     2.229588     0.084064   \n",
       "ACH-002669     4.472488     4.397118  ...     0.189034     0.400538   \n",
       "ACH-001858     5.410748     3.401903  ...     1.097611     0.400538   \n",
       "ACH-001997     4.469886     3.463361  ...     0.831877     0.847997   \n",
       "ACH-000052     3.945795     4.469886  ...     1.244887     1.207893   \n",
       "\n",
       "            AC098582.1 (8916)  DUS4L-BCAP29 (115253422)  \\\n",
       "CellLine                                                  \n",
       "ACH-001113           0.201634                  2.130931   \n",
       "ACH-001289           0.321928                  1.464668   \n",
       "ACH-001339           0.831877                  2.946731   \n",
       "ACH-001538           0.298658                  1.641546   \n",
       "ACH-000242           0.084064                  1.910733   \n",
       "...                       ...                       ...   \n",
       "ACH-000285           1.310340                  3.039138   \n",
       "ACH-002669           0.356144                  1.327687   \n",
       "ACH-001858           0.613532                  1.992768   \n",
       "ACH-001997           1.292782                  2.153805   \n",
       "ACH-000052           0.000000                  1.956057   \n",
       "\n",
       "            C8orf44-SGK3 (100533105)  ELOA3B (728929)  NPBWR1 (2831)  \\\n",
       "CellLine                                                               \n",
       "ACH-001113                  0.555816         0.000000       0.275007   \n",
       "ACH-001289                  0.632268         0.000000       0.014355   \n",
       "ACH-001339                  0.475085         0.000000       0.084064   \n",
       "ACH-001538                  0.443607         0.000000       0.028569   \n",
       "ACH-000242                  0.000000         0.000000       0.464668   \n",
       "...                              ...              ...            ...   \n",
       "ACH-000285                  0.344828         0.000000       0.000000   \n",
       "ACH-002669                  0.000000         0.000000       0.014355   \n",
       "ACH-001858                  0.704872         0.000000       1.464668   \n",
       "ACH-001997                  0.687061         0.000000       0.000000   \n",
       "ACH-000052                  0.575312         0.042644       0.000000   \n",
       "\n",
       "            ELOA3D (100506888)  ELOA3 (162699)  CDR1 (1038)  \n",
       "CellLine                                                     \n",
       "ACH-001113                 0.0        0.000000     0.000000  \n",
       "ACH-001289                 0.0        0.000000     0.000000  \n",
       "ACH-001339                 0.0        0.000000     0.042644  \n",
       "ACH-001538                 0.0        0.000000     0.000000  \n",
       "ACH-000242                 0.0        0.000000     0.000000  \n",
       "...                        ...             ...          ...  \n",
       "ACH-000285                 0.0        0.475085     0.042644  \n",
       "ACH-002669                 0.0        0.000000     0.000000  \n",
       "ACH-001858                 0.0        0.000000     0.526069  \n",
       "ACH-001997                 0.0        0.000000     0.000000  \n",
       "ACH-000052                 0.0        0.176323     0.056584  \n",
       "\n",
       "[1408 rows x 19193 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "victorian-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.81 s, sys: 3.87 ms, total: 5.82 s\n",
      "Wall time: 5.83 s\n"
     ]
    }
   ],
   "source": [
    "%time Joint_data = preprocess(Essentiality, Expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-consequence",
   "metadata": {},
   "source": [
    "### Val Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cells, val_cells = train_test_split(list(Joint_data.keys()), test_size=0.15)\n",
    "\n",
    "train_data = JointDataset(Joint_data, train_cells )\n",
    "val_data =  JointDataset(Joint_data, val_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-slope",
   "metadata": {},
   "source": [
    "### Model definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "divided-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_loss(anchEmbeddings, posEmbeddings, negEmbeddings, dist_metric=\"cos\"):\n",
    "\n",
    "#     if dist_metric.strip().lower() == \"cos\":\n",
    "#         dist_function = lambda x, y: 1.0 - F.cosine_similarity(x, y)\n",
    "        \n",
    "#     elif dist_metric.strip().lower() == \"eucl\":\n",
    "#         dist_function = nn.PairwiseDistance(p=2)\n",
    "        \n",
    "#     else:\n",
    "#         raise ValueError(f\"Triplet loss metric is invalid: {dist_metric}\")\n",
    "        \n",
    "    \n",
    "    triplet_loss = TripletMarginLoss(p=2, margin=margin)\n",
    "\n",
    "    TLoss = triplet_loss(anchEmbeddings, posEmbeddings, negEmbeddings)\n",
    "\n",
    "    return TLoss\n",
    "\n",
    "\n",
    "def compute_KL_loss(mu, logvar):\n",
    "    if lambda_>0:\n",
    "        KLloss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return lambda_ * KLloss\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def train(loader):\n",
    "    \n",
    "    model_ess.train()\n",
    "    model_exp.train()\n",
    "       \n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        \n",
    "        data_ess, data_exp = batch[0] , batch[1]\n",
    "        \n",
    "        #  rna_recon, rna_latents, rna_mu, rna_logvar\n",
    "        decoded_ess, latent_ess, mu_ess, logvar_ess = model_ess(data_ess)\n",
    "        decoded_exp, latent_exp, mu_exp, logvar_exp = model_exp(data_exp)\n",
    "\n",
    "        \n",
    "        # Compute lossese\n",
    "        loss_ess = MSELoss(data_ess, decoded_ess)\n",
    "        loss_exp = MSELoss(data_exp, decoded_exp)\n",
    "        kl_loss = compute_KL_loss(mu_ess, logvar_ess) + compute_KL_loss(mu_exp, logvar_exp)\n",
    "        \n",
    "        contrastive_loss = get_triplet_loss(latent_exp,\n",
    "                                            latent_ess,\n",
    "                                            latent_ess[torch.randperm(latent_ess.size()[0])])\n",
    "        \n",
    "        total_loss = alpha*(loss_ess + loss_exp) + (beta)* contrastive_loss + (1-alpha-beta)* kl_loss\n",
    "        \n",
    "        #print(f\"loss_ess: {loss_ess}, loss_exp:{loss_exp}, kl_loss:{kl_loss}, batch_loss:{total_loss}\")\n",
    "#         rna_recon_loss = criterion_reconstruct(rna_inputs, rna_recon)\n",
    "#         image_recon_loss = criterion_reconstruct(image_inputs, image_recon)\n",
    "#         kl_loss = compute_KL_loss(rna_mu, rna_logvar) + compute_KL_loss(image_mu, image_logvar)\n",
    "#         clf_loss = 0.5*criterion_classify(rna_scores, image_labels) + 0.5*criterion_classify(image_scores, rna_labels)\n",
    "#         loss = args.alpha*(rna_recon_loss + image_recon_loss) + clf_loss + kl_loss\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "        # Backpropagation\n",
    "        optimizer_ess.zero_grad()\n",
    "        optimizer_exp.zero_grad()\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer_ess.step() # update parameters\n",
    "        optimizer_exp.step()\n",
    "        \n",
    "        \n",
    "        train_loss += total_loss.item()\n",
    "        \n",
    "    return train_loss / len(loader)\n",
    "\n",
    "\n",
    "def generate_embeddings(loader):\n",
    "    \n",
    "    model_ess.eval()\n",
    "    model_exp.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    latents = []\n",
    "    latents_ess = []\n",
    "    latents_exp = []\n",
    "    all_decoded_ess = []\n",
    "    all_decoded_exp = []\n",
    "    all_decoded_app = []\n",
    "    all_original_ess = []\n",
    "    all_original_exp = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            \n",
    "            data_ess, data_exp = batch[0] , batch[1]\n",
    "            \n",
    "            decoded_ess, latent_ess, mu_ess, logvar_ess = model_ess(data_ess)\n",
    "            decoded_exp, latent_exp, mu_exp, logvar_exp = model_exp(data_exp)\n",
    "            \n",
    "            latents.append(torch.cat((latent_ess, latent_exp), dim=1))\n",
    "            \n",
    "            all_decoded_ess.append(decoded_ess)\n",
    "            all_decoded_exp.append(decoded_exp)\n",
    "            all_decoded_app.append(torch.cat((decoded_ess, decoded_exp), dim=1))\n",
    "            \n",
    "            all_original_ess.append(data_ess)\n",
    "            all_original_exp.append(data_exp)\n",
    "\n",
    "            \n",
    "    latents = torch.cat(latents, dim=0)\n",
    "    all_decoded_ess = torch.cat(all_decoded_ess, dim=0)\n",
    "    all_decoded_exp = torch.cat(all_decoded_exp, dim=0)\n",
    "    all_decoded_app = torch.cat(all_decoded_app, dim=0)\n",
    "    \n",
    "    all_original_ess = torch.cat(all_original_ess, dim=0)\n",
    "    all_original_exp = torch.cat(all_original_exp, dim=0)\n",
    "    \n",
    "    \n",
    "    return latents, all_decoded_ess, all_decoded_exp, all_decoded_app, all_original_ess, all_original_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "better-transcription",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 1 of 10\n",
      "-------------------------------\n",
      "\tET: 7.6537487506866455\n",
      "\n",
      "\tTrain Loss: 2.5203554305163296\n",
      "\n",
      "Epoch 2 of 10\n",
      "-------------------------------\n",
      "\tET: 7.521425247192383\n",
      "\n",
      "\tTrain Loss: 2.3057811043479224\n",
      "\n",
      "Epoch 3 of 10\n",
      "-------------------------------\n",
      "\tET: 7.055394172668457\n",
      "\n",
      "\tTrain Loss: 2.001492229374972\n",
      "\n",
      "Epoch 4 of 10\n",
      "-------------------------------\n",
      "\tET: 6.778824329376221\n",
      "\n",
      "\tTrain Loss: 1.717294920574535\n",
      "\n",
      "Epoch 5 of 10\n",
      "-------------------------------\n",
      "\tET: 7.1564788818359375\n",
      "\n",
      "\tTrain Loss: 1.467691112648357\n",
      "\n",
      "Epoch 6 of 10\n",
      "-------------------------------\n",
      "\tET: 6.868217945098877\n",
      "\n",
      "\tTrain Loss: 1.133436137979681\n",
      "\n",
      "Epoch 7 of 10\n",
      "-------------------------------\n",
      "\tET: 8.58285903930664\n",
      "\n",
      "\tTrain Loss: 0.94749946214936\n",
      "\n",
      "Epoch 8 of 10\n",
      "-------------------------------\n",
      "\tET: 8.085248231887817\n",
      "\n",
      "\tTrain Loss: 0.794519379734993\n",
      "\n",
      "Epoch 9 of 10\n",
      "-------------------------------\n",
      "\tET: 7.63398814201355\n",
      "\n",
      "\tTrain Loss: 0.6389235122637316\n",
      "\n",
      "Epoch 10 of 10\n",
      "-------------------------------\n",
      "\tET: 7.8243088722229\n",
      "\n",
      "\tTrain Loss: 0.597838741811839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "#n_input, latent_variable_size, n_hidden=512\n",
    "\n",
    "random_cell_line = random.choice(list(Joint_data.keys()))\n",
    "n_input_ess = Joint_data[random_cell_line][\"data_ess\"].size(0)\n",
    "n_input_exp = Joint_data[random_cell_line][\"data_exp\"].size(0)\n",
    "\n",
    "latent_size = int(10e3) #1024\n",
    "batch_size = 40\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "margin = 1.0\n",
    "alpha=0.1\n",
    "lambda_ = 1e-08 #0.00000001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_ess = FC_Autoencoder(n_input_ess, latent_size) \n",
    "model_exp = FC_Autoencoder(n_input_exp, latent_size) \n",
    "\n",
    "MSELoss = nn.MSELoss()\n",
    "\n",
    "optimizer_ess = optim.Adam(model_ess.parameters(), lr=lr)\n",
    "optimizer_exp = optim.Adam(model_exp.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimal_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "    train_loss = train(train_loader)\n",
    "    if train_loss < optimal_loss:\n",
    "        \n",
    "        optimal_loss = train_loss \n",
    "        torch.save(model_ess.cpu().state_dict(), \"saved-models/model_ess.pth\")\n",
    "        torch.save(model_exp.cpu().state_dict(), \"saved-models/model_exp.pth\")\n",
    "\n",
    "    print(f'\\tET: {time.time() - start_time}\\n')\n",
    "    print(f'\\tTrain Loss: {train_loss}\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "threaded-track",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latents,\\\n",
    "all_decoded_ess, all_decoded_exp, all_decoded_app,\\\n",
    "all_original_ess, all_original_exp = generate_embeddings(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "about-jones",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/users/jararweh/.conda/envs/DeepVul/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tsne = TSNE(n_components=2)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "latents_tsne = tsne.fit_transform(scaler.fit_transform(latents))\n",
    "\n",
    "all_decoded_ess_tsne = tsne.fit_transform(scaler.fit_transform(all_decoded_ess))\n",
    "all_decoded_exp_tsne = tsne.fit_transform(scaler.fit_transform(all_decoded_exp))\n",
    "all_decoded_app_tsne = tsne.fit_transform(scaler.fit_transform(all_decoded_app))\n",
    "\n",
    "all_original_ess_tsne = tsne.fit_transform(scaler.fit_transform(all_original_ess))\n",
    "all_original_exp_tsne = tsne.fit_transform(scaler.fit_transform(all_original_exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-independence",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(latents_tsne[:, 0], latents_tsne[:, 1], label='Common Latent space')\n",
    "\n",
    "\n",
    "#plt.scatter(all_decoded_app_tsne[:, 0], all_decoded_app_tsne[:, 1])\n",
    "plt.scatter(all_decoded_ess_tsne[:, 0], all_decoded_ess_tsne[:, 1], label='Gene essentiality')\n",
    "plt.scatter(all_decoded_exp_tsne[:, 0], all_decoded_exp_tsne[:, 1], label='Gene expression')\n",
    "\n",
    "# plt.scatter(all_original_ess_tsne[:, 0], all_original_ess_tsne[:, 1], label='Gene essentiality')\n",
    "# plt.scatter(all_original_exp_tsne[:, 0], all_original_exp_tsne[:, 1], label='Gene expression')\n",
    "plt.legend(loc='lower right', prop={'size': 5.5})\n",
    "plt.title(\"Mapping gene essentiality and gene expression to a common latent space\", fontsize=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-encounter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-devon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(all_decoded_ess_tsne[:, 0], all_decoded_ess_tsne[:, 1], label='Decoded gene essentiality')\n",
    "#plt.scatter(all_decoded_exp_tsne[:, 0], all_decoded_exp_tsne[:, 1], label='Gene expression')\n",
    "\n",
    "plt.scatter(all_original_ess_tsne[:, 0], all_original_ess_tsne[:, 1], label='Original gene essentiality')\n",
    "#plt.scatter(all_original_exp_tsne[:, 0], all_original_exp_tsne[:, 1], label='Gene expression')\n",
    "\n",
    "plt.legend(loc='lower right', prop={'size': 5.5})\n",
    "plt.title(\"Gene essentiality mapped to an approximate latent space\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-launch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(all_decoded_ess_tsne[:, 0], all_decoded_ess_tsne[:, 1], label='Decoded gene essentiality')\n",
    "plt.scatter(all_decoded_exp_tsne[:, 0], all_decoded_exp_tsne[:, 1], label='Decoded Gene expression')\n",
    "\n",
    "#plt.scatter(all_original_ess_tsne[:, 0], all_original_ess_tsne[:, 1], label='Original gene essentiality')\n",
    "plt.scatter(all_original_exp_tsne[:, 0], all_original_exp_tsne[:, 1], label='Gene expression')\n",
    "\n",
    "plt.legend(loc='lower right', prop={'size': 5.5})\n",
    "plt.title(\"Gene expression mapped to an approximate latent space\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-vienna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-sodium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(latents_tsne[:, 0], latents_tsne[:, 1], label='Common Latent space')\n",
    "\n",
    "\n",
    "plt.scatter(all_decoded_app_tsne[:, 0], all_decoded_app_tsne[:, 1], label='Decoded gene information')\n",
    "# plt.scatter(all_decoded_ess_tsne[:, 0], all_decoded_ess_tsne[:, 1], label='Gene essentiality')\n",
    "# plt.scatter(all_decoded_exp_tsne[:, 0], all_decoded_exp_tsne[:, 1], label='Gene expression')\n",
    "\n",
    "# plt.scatter(all_original_ess_tsne[:, 0], all_original_ess_tsne[:, 1], label='Gene essentiality')\n",
    "# plt.scatter(all_original_exp_tsne[:, 0], all_original_exp_tsne[:, 1], label='Gene expression')\n",
    "plt.legend(loc='lower right', prop={'size': 5.5})\n",
    "plt.title(\"Mapping gene information to a common latent space\", fontsize=9)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DeepVul]",
   "language": "python",
   "name": "conda-env-.conda-DeepVul-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
